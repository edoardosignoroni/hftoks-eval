#CURRENT OBJECTIVE

train tokenizers for same sizes as Gowda and May, 2021

reproduce their results and plot them

train HFToks and plot Freq@95% and Length (in toks) vs vocab_size

our Freq@95% should be HIGHER, and Length should be LOWER

If possible then train NMT for each tokenizer and plot that

Copy of LoResMT 2021 shared task to experiment with tokenizer vocabulary size and BLEU scores in Low Res

