	lang	tokenizer	vocab_size	freq@95%	avg_len	weighted
20	en	bpe	6000.0	2	25.118186595327952	27.25246578068027
1	en	bpe	4000.0	2	27.158505708689628	47.06501289607576
2	en	bpe	500.0	2	47.53040653513591	846.304147768356
6	en	bpe	750.0	2	41.51717384034777	481.09486036531007
8	en	bpe	3000.0	2	28.901590789662254	70.05979430944987
11	en	bpe	8000.0	1	23.9537094539722	18.657501551109636
19	en	bpe	1500.0	3	34.39640758610806	180.92097310609856
18	en	hft	750.0	3	40.31648593130464	520.3156761368132
15	en	hft	6000.0	10	22.701428366693737	23.340574925910385
14	en	hft	8000.0	6	21.641761811493815	14.380830352832643
13	en	hft	500.0	2	47.147709358429275	917.8027317160265
10	en	hft	3000.0	34	26.421917546457745	72.15345319561715
5	en	hft	4000.0	21	24.656953136196435	45.483177941916544
9	en	hft	1500.0	34	32.098218124492426	201.12039506366511
12	en	unigram	750.0	8	38.23737639134381	339.0372545174972
7	en	unigram	4000.0	9	25.60125161228682	33.18760629342079
4	en	unigram	3000.0	13	26.940428987722733	50.23362336411939
16	en	unigram	8000.0	3	23.39540438542015	11.86598205412814
17	en	unigram	6000.0	5	24.158219079921654	18.286149161204477
3	en	unigram	500.0	2	43.060383127119856	585.7537352887923
0	en	unigram	1500.0	36	31.55620312425357	133.23126911947085
