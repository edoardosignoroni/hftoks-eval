	lang	tokenizer	vocab_size	train	token
0	ga	ga_bpe_hft_pretok_0.5k	500	0.16338872909545898	0.6137270927429199
1	ga	ga_bpe_hft_pretok_0.75k	750	0.16820383071899414	0.5783176422119141
2	ga	ga_bpe_hft_pretok_1.5k	1500	0.2120218276977539	0.6837377548217773
3	ga	ga_bpe_hft_pretok_3.0k	3000	0.2286241054534912	0.5856227874755859
4	ga	ga_bpe_hft_pretok_4.0k	4000	0.2639129161834717	0.6795198917388916
5	ga	ga_bpe_hft_pretok_6.0k	6000	0.33553218841552734	0.6049456596374512
6	ga	ga_bpe_hft_pretok_8.0k	8000	0.35974884033203125	0.5587177276611328
