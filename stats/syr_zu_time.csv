	dataset	lang	tokenizer	vocab_size	train	token
0	syr_zu	zu	zu_hft_0.5k	500	6.273588418960571	2.1149158477783203
1	syr_zu	zu	zu_hft_0.75k	750	9.701860666275024	2.5086042881011963
2	syr_zu	zu	zu_hft_1.5k	1500	22.310085773468018	2.223994493484497
3	syr_zu	zu	zu_hft_3.0k	3000	47.35856318473816	2.433397054672241
4	syr_zu	zu	zu_hft_4.0k	4000	64.88805913925171	2.5872817039489746
5	syr_zu	zu	zu_hft_6.0k	6000	107.25629472732544	2.601562738418579
6	syr_zu	zu	zu_hft_8.0k	8000	164.91243505477905	2.9755005836486816
