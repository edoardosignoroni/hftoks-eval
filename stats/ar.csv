	lang	tokenizer	vocab_size	freq@95%	avg_len	weighted
10	ar	bpe	6000.0	3	22.080959423831263	39.470370749807174
3	ar	bpe	1500.0	8	28.14818982702077	222.50658911280385
18	ar	bpe	750.0	11	32.449842453861486	561.203998369676
5	ar	bpe	500.0	11	35.3170535656871	971.3609580506715
6	ar	bpe	4000.0	4	23.58751848755707	65.3448331187559
7	ar	bpe	8000.0	3	21.088515208025207	27.75987078858198
14	ar	bpe	3000.0	5	24.786090926628514	92.73748268087338
1	ar	hft	500.0	42	36.582759951128544	1125.8145569884396
2	ar	hft	1500.0	116	28.000932415921806	258.95316229007915
8	ar	hft	6000.0	19	21.374638286926885	41.16902327092417
19	ar	hft	3000.0	48	24.287248408462478	103.6938518550722
16	ar	hft	8000.0	13	20.3246415021542	27.727450547617497
15	ar	hft	4000.0	33	23.022538743489164	71.76930711918084
13	ar	hft	750.0	200	32.89794868497203	668.1700036403349
17	ar	unigram	8000.0	8	21.23278245771976	21.79075240869768
0	ar	unigram	1500.0	60	28.036942961867403	193.3760235946916
11	ar	unigram	500.0	184	35.18140312520095	853.9059375783853
9	ar	unigram	3000.0	25	24.781814674297472	77.25621500952415
4	ar	unigram	4000.0	18	23.629766574496816	53.05441877230743
12	ar	unigram	6000.0	11	22.15111568387885	31.620691928691016
20	ar	unigram	750.0	139	32.2967011767732	485.06416893462324
