	lang	tokenizer	vocab_size	train	token
0	cs	cs_unigram_hft_pretok_0.5k	500	2.215717315673828	2.031475305557251
1	cs	cs_unigram_hft_pretok_0.75k	750	2.1570794582366943	2.0327110290527344
2	cs	cs_unigram_hft_pretok_1.5k	1500	2.157275438308716	1.9873013496398926
3	cs	cs_unigram_hft_pretok_3.0k	3000	2.048919677734375	1.9916577339172363
4	cs	cs_unigram_hft_pretok_4.0k	4000	2.0614113807678223	2.028903007507324
5	cs	cs_unigram_hft_pretok_6.0k	6000	1.7917098999023438	1.9310336112976074
6	cs	cs_unigram_hft_pretok_8.0k	8000	1.8388941287994385	2.0408990383148193
