	lang	tokenizer	vocab_size	train	token
0	jak	jak_bpe_hft_pretok_0.5k	500	0.1889629364013672	0.8550660610198975
1	jak	jak_bpe_hft_pretok_0.75k	750	0.19367527961730957	0.9313821792602539
2	jak	jak_bpe_hft_pretok_1.5k	1500	0.21109557151794434	0.8650712966918945
3	jak	jak_bpe_hft_pretok_3.0k	3000	0.24247074127197266	0.8761136531829834
4	jak	jak_bpe_hft_pretok_4.0k	4000	0.2763707637786865	0.9062116146087646
5	jak	jak_bpe_hft_pretok_6.0k	6000	0.31896519660949707	0.8967339992523193
6	jak	jak_bpe_hft_pretok_8.0k	8000	0.4461855888366699	0.9933254718780518
