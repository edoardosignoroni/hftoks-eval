	lang	tokenizer	vocab_size	train	token
0	it	it_unigram_hft_pretok_0.5k	500	2.038764476776123	2.0462207794189453
1	it	it_unigram_hft_pretok_0.75k	750	2.0393402576446533	2.078829765319824
2	it	it_unigram_hft_pretok_1.5k	1500	1.907029390335083	1.9671790599822998
3	it	it_unigram_hft_pretok_3.0k	3000	1.825570821762085	1.9660413265228271
4	it	it_unigram_hft_pretok_4.0k	4000	1.8627700805664062	2.0099117755889893
5	it	it_unigram_hft_pretok_6.0k	6000	1.7511005401611328	2.0687451362609863
6	it	it_unigram_hft_pretok_8.0k	8000	1.649449348449707	2.0163991451263428
