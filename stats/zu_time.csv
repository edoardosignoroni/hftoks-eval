	lang	tokenizer	vocab_size	train	token
0	zu	zu_unigram_hft_pretok_0.5k	500	1.2917015552520752	0.5939803123474121
1	zu	zu_unigram_hft_pretok_0.75k	750	1.2107017040252686	0.5733160972595215
2	zu	zu_unigram_hft_pretok_1.5k	1500	1.0724093914031982	0.5626721382141113
3	zu	zu_unigram_hft_pretok_3.0k	3000	0.9325199127197266	0.5369858741760254
4	zu	zu_unigram_hft_pretok_4.0k	4000	0.9029231071472168	0.5523955821990967
5	zu	zu_unigram_hft_pretok_6.0k	6000	0.7806711196899414	0.587822437286377
6	zu	zu_unigram_hft_pretok_8.0k	8000	0.7078735828399658	0.5727496147155762
