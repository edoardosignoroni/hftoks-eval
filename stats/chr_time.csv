	lang	tokenizer	vocab_size	train	token
0	chr	chr_unigram_hft_pretok_0.5k	500	0.7844398021697998	0.4492526054382324
1	chr	chr_unigram_hft_pretok_0.75k	750	0.7041771411895752	0.44330549240112305
2	chr	chr_unigram_hft_pretok_1.5k	1500	0.7411494255065918	0.43409228324890137
3	chr	chr_unigram_hft_pretok_3.0k	3000	0.6284317970275879	0.458803653717041
4	chr	chr_unigram_hft_pretok_4.0k	4000	0.5309972763061523	0.40276455879211426
5	chr	chr_unigram_hft_pretok_6.0k	6000	0.48499035835266113	0.4006509780883789
6	chr	chr_unigram_hft_pretok_8.0k	8000	0.43188953399658203	0.3907458782196045
