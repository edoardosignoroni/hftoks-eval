	lang	tokenizer	vocab_size	freq@95%	avg_len	weighted
10	fi	bpe	3000.0	6	30.126356408463472	133.51836153064187
3	fi	bpe	1500.0	19	34.7772252868205	340.83767952281676
4	fi	bpe	6000.0	3	26.50736798487556	54.805657835746615
6	fi	bpe	750.0	31	40.78771398233756	882.8670800683992
7	fi	bpe	500.0	56	45.465723978970814	1554.3701667303042
14	fi	bpe	4000.0	5	28.458705617279154	91.91768217356532
13	fi	bpe	8000.0	2	25.279879833216793	38.07102721482358
18	fi	hft	6000.0	26	23.451246989355916	52.39548348027044
17	fi	hft	4000.0	44	25.30065004014192	89.82055759707042
16	fi	hft	500.0	164	41.95276202315282	1390.6417595514774
20	fi	hft	8000.0	17	22.263097920389505	34.88716621919117
9	fi	hft	750.0	322	37.857638619117914	859.0003655446305
5	fi	hft	3000.0	69	26.952477145002977	136.55636220604563
19	fi	hft	1500.0	180	31.831093155155	361.38243738452286
11	fi	unigram	500.0	388	43.45370730065004	1290.1726180375426
12	fi	unigram	3000.0	32	28.757024836195065	96.79085556537191
8	fi	unigram	4000.0	21	27.260249138891048	65.23280767228748
15	fi	unigram	1500.0	81	33.0945277497216	257.0668350497167
2	fi	unigram	8000.0	8	24.411182762282134	25.091213075588687
1	fi	unigram	750.0	212	38.885867453966284	707.1810593532776
0	fi	unigram	6000.0	12	25.484551834874264	37.26569055041196
