	lang	tokenizer	vocab_size	freq@95%	avg_len	weighted
10	fi	bpe	3000.0	6	30.126356408463472	147.68979478367768
3	fi	bpe	1500.0	19	34.7772252868205	377.066017274349
4	fi	bpe	6000.0	3	26.50736798487556	60.563935190993064
6	fi	bpe	750.0	31	40.78771398233756	978.4782256920985
7	fi	bpe	500.0	56	45.465723978970814	1725.7122323870603
14	fi	bpe	4000.0	5	28.458705617279154	101.61154399871799
13	fi	bpe	8000.0	2	25.279879833216793	42.03766168862404
18	fi	hft	6000.0	26	23.451246989355916	55.48627715394974
17	fi	hft	4000.0	44	25.30065004014192	95.4248662547671
16	fi	hft	500.0	164	41.95276202315282	1538.2791419320022
20	fi	hft	8000.0	17	22.263097920389505	36.94188094236067
9	fi	hft	750.0	322	37.857638619117914	944.4702428251514
5	fi	hft	3000.0	69	26.952477145002977	145.46847212429557
19	fi	hft	1500.0	180	31.831093155155	389.7511837432272
11	fi	unigram	500.0	388	43.45370730065004	1420.9489823341814
12	fi	unigram	3000.0	32	28.757024836195065	104.17104936005967
8	fi	unigram	4000.0	21	27.260249138891048	70.27100467193482
15	fi	unigram	1500.0	81	33.0945277497216	277.87748986165593
2	fi	unigram	8000.0	8	24.411182762282134	27.02352959647121
1	fi	unigram	750.0	212	38.885867453966284	772.7989987882158
0	fi	unigram	6000.0	12	25.484551834874264	40.13906725499129
