	dataset	lang	tokenizer	vocab_size	train	token
0	en_ga	ga	ga_hft_0.5k	500	2.56955623626709	2.355928659439087
1	en_ga	ga	ga_hft_0.75k	750	4.248405933380127	2.6199581623077393
2	en_ga	ga	ga_hft_1.5k	1500	10.618996381759644	2.681901454925537
3	en_ga	ga	ga_hft_3.0k	3000	27.375499725341797	2.9331867694854736
4	en_ga	ga	ga_hft_4.0k	4000	38.8452787399292	2.971226692199707
5	en_ga	ga	ga_hft_6.0k	6000	63.495386362075806	3.0028433799743652
6	en_ga	ga	ga_hft_8.0k	8000	89.98708486557007	3.1449713706970215
