	dataset	lang	tokenizer	vocab_size	train	token
0	en_ga	en	en_hft_0.5k	500	2.216036558151245	1.9580585956573486
1	en_ga	en	en_hft_0.75k	750	3.060133934020996	2.060183525085449
2	en_ga	en	en_hft_1.5k	1500	7.415022134780884	2.216653347015381
3	en_ga	en	en_hft_3.0k	3000	18.077742099761963	2.4240050315856934
4	en_ga	en	en_hft_4.0k	4000	28.583660364151	2.5183017253875732
5	en_ga	en	en_hft_6.0k	6000	50.487568378448486	2.815852642059326
6	en_ga	en	en_hft_8.0k	8000	80.34558296203613	2.7548701763153076
