	dataset	lang	tokenizer	vocab_size	train	token
0	lt_en	lt	lt_bpe_0.5k	500	14.439450025558472	77.72907710075378
1	lt_en	lt	lt_bpe_1.0k	1000	15.50147533416748	68.27990698814392
2	lt_en	lt	lt_bpe_2.0k	2000	16.158740043640137	83.09614419937134
3	lt_en	lt	lt_bpe_4.0k	4000	17.52887487411499	68.37466168403625
4	lt_en	lt	lt_bpe_8.0k	8000	19.598048210144043	64.03784346580505
5	lt_en	lt	lt_bpe_16.0k	16000	25.69085144996643	61.94704270362854
6	lt_en	lt	lt_bpe_32.0k	32000	71.17434453964233	72.3143048286438
