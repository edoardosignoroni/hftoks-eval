	dataset	lang	tokenizer	vocab_size	train	token
0	lt_en	lt	lt_char_0.262k	262	3.2456579208374023	43.25708556175232
