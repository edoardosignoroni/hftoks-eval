	dataset	lang	tokenizer	vocab_size	train	token
0	lt_en	lt	lt_unigram_0.5k	500	51.577529191970825	34.91351246833801
1	lt_en	lt	lt_unigram_0.75k	750	51.73295187950134	32.82315135002136
2	lt_en	lt	lt_unigram_1.5k	1500	49.42931866645813	30.109076738357544
3	lt_en	lt	lt_unigram_3.0k	3000	49.00518536567688	36.728370904922485
4	lt_en	lt	lt_unigram_4.0k	4000	47.6573429107666	28.422220706939697
5	lt_en	lt	lt_unigram_6.0k	6000	46.734485387802124	28.28309440612793
6	lt_en	lt	lt_unigram_8.0k	8000	46.94349265098572	28.416922092437744
