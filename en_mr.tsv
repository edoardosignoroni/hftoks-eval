	tokenizer_type	vocab_size	freq@95%	avg_len
6	char	141.0	1	105.50623417570344
20	char	188.0	1	100.26169206516028
1	bpe	500.0	2	43.890460039172595
4	unigram	500.0	2	43.060383127119856
22	bpe	500.0	5	47.69956527970191
17	unigram	500.0	5	46.87082596856638
25	bpe	1000.0	10	37.94549276262361
2	bpe	1000.0	11	36.008933263268524
23	unigram	1000.0	37	36.86112836191659
7	unigram	1000.0	53	35.208761286007736
19	unigram	2000.0	34	29.838389146323987
18	bpe	2000.0	9	30.881383461520088
12	unigram	2000.0	25	29.382601633783977
9	bpe	2000.0	9	30.04543065972388
14	unigram	4000.0	13	25.210863230306217
21	bpe	4000.0	6	25.664739884393065
5	unigram	4000.0	9	25.60125161228682
0	bpe	4000.0	4	25.78039459227058
15	unigram	8000.0	4	22.359719103807386
16	bpe	8000.0	3	21.997468112549562
11	unigram	8000.0	3	23.39540438542015
10	bpe	8000.0	2	23.028376248029428
13	bpe	16000.0	2	19.508192805617924
3	bpe	16000.0	1	21.4249749199828
8	bpe	32000.0	1	20.573687479099984
24	bpe	32000.0	1	17.719629293460088
